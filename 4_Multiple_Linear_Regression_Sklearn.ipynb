{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Multiple Linear Regression\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Until now we were just looking at simple linear regression problems. But linear regression can also be used with more than one explanatory variable to describe the target variable."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Learning Objectives\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "At the end of this notebook you should be able to\n",
    "- apply multiple linear regression with scikit-learn.\n",
    "- interpret multiple linear regression models.\n",
    "- explain why it is better to use **adjusted $R^2$** than $R^2$ to compare multiple linear regression models."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recap\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Multiple Regression Model\n",
    "\n",
    " "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple linear regression is very similar to simple linear regression except that the dependent variable $y$ is described by $k$ independent variables $x_1, \\dots, x_k$  \n",
    "\n",
    "$$\n",
    "y = b_0 + b_1 x_1 + b_2 x_2 + \\dots + b_k x_k + e\n",
    "$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The formula for our **predicted model** is given by\n",
    "\n",
    "$$\\hat{y} = b_0  + b_1  x_1 + b_2  x_2 + \\dots + b_k  x_k$$\n",
    "\n",
    "where $b_0$ is the estimated intercept and $b_1, b_2,$... are the coefficients of our features.\n",
    "* **Intercept**: The interpretation stays the same as for simple linear regression. It is the value for $y$ when all $x$ are 0.\n",
    "* **Coefficients**: Regarding the interpretation of the coefficients we need to be more precise: $b_i$ is the change in $y$ given a unit change in $x_i$ while **holding all other variables constant**  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's start with an example\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example we will use a car data set again. This time it will be a bit more extensive with more observations and features but our aim is still to predict `mpg` based on different car characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T10:31:50.562671Z",
     "start_time": "2020-04-21T10:31:48.179498Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Set figure stile and size for entire notebook\n",
    "sns.set_style(\"ticks\")\n",
    "plt.rcParams[\"figure.figsize\"] = (7,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T10:31:50.603684Z",
     "start_time": "2020-04-21T10:31:50.565714Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Import dataset \n",
    "cars = pd.read_csv(\"data/cars_multivariate.csv\")\n",
    "cars.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Simple Linear Regression\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, we will first use a simple linear regression model with the feature `horsepower` and see how well it fits our data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T10:31:50.781539Z",
     "start_time": "2020-04-21T10:31:50.606733Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Plot relationship between horsepower and mpg \n",
    "plt.scatter(cars.horsepower, cars.mpg)\n",
    "plt.ylabel('mpg')\n",
    "plt.xlabel('horsepower');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T10:31:51.244108Z",
     "start_time": "2020-04-21T10:31:51.214251Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Define feature and target variable\n",
    "X = cars[['horsepower']]\n",
    "y = cars['mpg']\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit linear regression model\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X, y)\n",
    "\n",
    "# Calculate r-squared \n",
    "y_hat = lin_reg.predict(X)\n",
    "print(\"R-squared:\", round(r2_score(y, y_hat),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot data with regression line\n",
    "plt.scatter(X, y)\n",
    "plt.plot(X, y_hat, '-', color='orange', linewidth=2)\n",
    "plt.ylabel('mpg')\n",
    "plt.xlabel('horsepower');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the $R^2$ the feature `horsepower` can explain 60.6% of the variance in our target variable. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Multiple Linear Regression  \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of using `horsepower` as the only independent variable to predict `mpg`, we might want to include other independent variables in the model to improve the fit. Let's try to add `weight` to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T10:31:51.673694Z",
     "start_time": "2020-04-21T10:31:51.294371Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Plot relationship between weight and mpg \n",
    "# We can use seaborns .lmplot function to plot our data including a regression line \n",
    "sns.lmplot(x='weight', y='mpg', data=cars, ci=None);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T10:31:51.688307Z",
     "start_time": "2020-04-21T10:31:51.676705Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Define model input X with two features\n",
    "X2 = cars[['horsepower', 'weight']]\n",
    "y2 = cars.mpg\n",
    "\n",
    "X2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T10:31:51.703899Z",
     "start_time": "2020-04-21T10:31:51.690344Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Fit linear regression model\n",
    "lin_reg2 = LinearRegression()\n",
    "lin_reg2.fit(X2, y2)\n",
    "\n",
    "# Calculate intercept and coefficient\n",
    "intercept = lin_reg2.intercept_\n",
    "coefficients = lin_reg2.coef_\n",
    "print(\"Intercept:\", intercept.round(4))\n",
    "print(\"Coefficients:\", coefficients.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T10:31:51.703899Z",
     "start_time": "2020-04-21T10:31:51.690344Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate r-squared \n",
    "y_hat2 = lin_reg2.predict(X2)\n",
    "print(\"R-squared:\", round(r2_score(y2, y_hat2),3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Model Interpretation\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does this Model describe the variance of `mpg` better than the simple linear regression? It seems so. This model explains about 70% of the variation in `mpg`.\n",
    "\n",
    "Our multiple regression model is give by  \n",
    "\n",
    "$$ \\hat{mpg} = 45.6402 - 0.0473 \\times horsepower - 0.0058 \\times weight $$\n",
    "\n",
    "Let's interpret what we can see here...\n",
    "* The expected `mpg` for a car with a `horsepower` and `weight` of 0, is 45.6402 (in theory...).\n",
    "* We would expect `mpg` to decrease by 0.0473 as `horsepower` goes up by 1,  **holding `weight` constant**.\n",
    "* We would expect `mpg` to decrease by 0.0058 as `weight` increases by 1, **holding `horsepower` constant**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Predicting for new cars\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the predicted `mpg` for a car with 200 `horsepower` and a `weight` of 3500?\n",
    "\n",
    "$$ \n",
    "\\hat{mpg} = 45.6402 - 0.0473 (200) - 0.0058 (3500) = 15.88 \n",
    "$$  \n",
    "\n",
    "\n",
    "We would expected the `mpg` of the car to be 15.88.\n",
    "This can of course also be calculated with our model. We only need to call the `.predict()`function and give it the values of X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions for new car with horsepower=200 and weight=3500\n",
    "new_car = pd.DataFrame({'horsepower': [200], 'weight': [3500]})\n",
    "y_prediction = lin_reg2.predict(new_car)\n",
    "print(\"Prediction for new car:\", y_prediction[0].round(3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Explore Multiple Regression\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, multiple linear regression is not so easy to display, but the use of only two independent variables predicting a dependent variable can still be displayed graphically with a 3D-plot.\n",
    "\n",
    "Now we will try to plot the data points and our adjusted linear model on the three axes (`horsepower`, `weight` and `mpg`). With two variables instead of one independent variable, our model is not represented by a line, but by a 2D plane.\n",
    "\n",
    "In the cell below, you will find the code for plotting this 3D plot, however, you need to define some variables first. \n",
    "\n",
    "The command \n",
    "```Python:\n",
    "%matplotlib widget\n",
    "```\n",
    "will enable interactive 3D-plots, so you can change your view on the data. (When the plot is not shown after executing the cell, just run the cell again... that should fix it :) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We adapted this plot from https://www.datarobot.com/blog/multiple-regression-using-statsmodels/#appendix\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Enable interactive plot\n",
    "%matplotlib widget\n",
    "\n",
    "# You need to define some variables for the intercept and coefficients of your model\n",
    "intercept = \n",
    "coef_horsepower = \n",
    "coef_weight =\n",
    "\n",
    "# Create horsepower/weight grid for the 3D plot\n",
    "xx1, xx2 = np.meshgrid(np.linspace(X2.horsepower.min(), X2.horsepower.max(), 100), \n",
    "                       np.linspace(X2.weight.min(), X2.weight.max(), 100))\n",
    "\n",
    "# Plot the hyperplane (HP) by evaluating the parameters on the grid\n",
    "# The following line is our regression equation \n",
    "Z = intercept + coef_horsepower * xx1 + coef_weight * xx2\n",
    "\n",
    "\n",
    "# Create 3D figure in matplotlib\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "ax = Axes3D(fig, azim=-115, elev=15, auto_add_to_figure=False)\n",
    "fig.add_axes(ax)\n",
    "\n",
    "# Plot the hyperplane\n",
    "surf = ax.plot_surface(xx1, xx2, Z, cmap=plt.cm.RdBu_r, alpha=0.8, linewidth=0)\n",
    "\n",
    "# Calculate residuals\n",
    "resid = y2 - y_hat2\n",
    "\n",
    "# Plot data points - points over the HP are white, points below are black\n",
    "ax.scatter(X2[resid >= 0].horsepower, X2[resid >= 0].weight, y2[resid >= 0], color='black', alpha=1.0, facecolor='white')\n",
    "ax.scatter(X2[resid < 0].horsepower, X2[resid < 0].weight, y2[resid < 0], color='black', alpha=1.0)\n",
    "\n",
    "# set axis labels\n",
    "ax.set_xlabel('horsepower')\n",
    "ax.set_ylabel('weight')\n",
    "ax.set_zlabel('mpg');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to disable the interactivity for the upcoming plots, we have to run `%matplotlib inline` again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Adding More Variables\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try to predict `mpg` using `displacement`, `horsepower`, `weight` and `acceleration`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T10:31:52.136486Z",
     "start_time": "2020-04-21T10:31:48.220Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Print correlation of variables\n",
    "cars[['displacement', 'horsepower', 'weight', 'acceleration']].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You see that there are quite some correlations between these variables! These correlations can also be seen in the scatter plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T10:31:52.137890Z",
     "start_time": "2020-04-21T10:31:48.223Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Plot pair plot of potential features\n",
    "sns.pairplot(cars[['displacement', 'horsepower', 'weight', 'acceleration']]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and fit model with multiple variables\n",
    "X3 = cars[['horsepower', 'weight', 'displacement', 'acceleration']]\n",
    "y3 = cars.mpg\n",
    "\n",
    "# Fit linear regression model\n",
    "lin_reg3 = LinearRegression()\n",
    "lin_reg3.fit(X3, y3)\n",
    "\n",
    "# Calculate intercept and coefficient\n",
    "intercept = lin_reg3.intercept_\n",
    "coefficients = lin_reg3.coef_\n",
    "print(\"Intercept:\", intercept.round(4))\n",
    "print(\"Coefficients:\", coefficients.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate r-squared \n",
    "y_hat3 = lin_reg3.predict(X3)\n",
    "print(\"R-squared:\", round(r2_score(y3, y_hat3),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "You should always question your model! Here are some questions you should be able to answer now:\n",
    "\n",
    "1. How good is the model fit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "2. What is the regression equation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<br>\n",
    "\n",
    "<details><summary>\n",
    "Click here for the solution\n",
    "</summary>\n",
    "$$\n",
    "\\hat{mpg} = 45.2511 - 0.0436 \\times horsepower - 0.0053 \\times weight - 0.0060 \\times displacement - 0.0231 \\times acceleration\n",
    "$$\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "3. How can we interpret the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## $R^2$ vs. Adjusted $R^2$\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whenever we deal with multiple linear regression $R^2$ should not be the metric of your choice to evaluate the model fit. By adding new features to our model the $R^2$ will either stay the same or increase, even if those additional features don't have any relationship with our target variable. This leads to an overwhelming temptation to add more and more features into our model. However, that's not a great idea! Usually we want to train a good model, **but** we want to do it in the simplest possible way. \n",
    "\n",
    "This is where **adjusted $R^2$** comes to help. Adjusted $R^2$ will penalize us for adding more features that actually don't improve our existing model. For a simple linear regression $R^2$ and adjusted $R^2$ will be the nearly the same. The more non-significant features we add to a model the larger the gap between those two metrics will be. Moreover, the adjusted $R^2$ is a useful metric when we want to compare several models with different amounts of features.\n",
    "\n",
    "The formula of the adjusted $R^2$ is:\n",
    "$$\n",
    "R_a^2 = 1 - \\frac{(1 - R^2) (n - 1)}{n - p - 1} \n",
    "$$  \n",
    "\n",
    "where $n$ is the number of observations in the data set and $p$ is the number of features.\n",
    "\n",
    "Unfortunately, scikit-learn does not provide a built-in function for calculating the adjusted $R^2$. But we can write our own function using the formula from above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function for calculating adjusted r-squared\n",
    "def adjusted_r_squared(r_squared, X):\n",
    "    adjusted_r2 = 1 - ((1 - r_squared) * (len(X) - 1) / (len(X) - X.shape[1] - 1))\n",
    "    return adjusted_r2 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the adjusted $R^2$ for the three models you've trained in this notebook. Which is the best model according to this metric?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summary\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We extend the linear regression model to include many explanatory variables/features.\n",
    "- All explanatory variables should be independent of each other.\n",
    "- $R^2$ allows use to measure how good a model fits the data.\n",
    "- Adjusted $R^2$ penalizes adding non-useful explanatory variables. It is useful for comparing models with different numbers of independent variables."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
